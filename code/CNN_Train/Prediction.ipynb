{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import scipy as sp \n",
    "import sklearn\n",
    "import random \n",
    "import time \n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('weatherHistory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.20000000e+00  8.90000000e-01  1.02361000e+03]\n",
      " [ 1.08888889e+00  9.20000000e-01  1.02990000e+03]\n",
      " [-1.12777778e+00  9.30000000e-01  1.03234000e+03]\n",
      " [ 6.11111111e+00  6.50000000e-01  1.02230000e+03]\n",
      " [ 2.68333333e+00  8.30000000e-01  1.02330000e+03]]\n"
     ]
    }
   ],
   "source": [
    "data = shuffle(data)\n",
    "\n",
    "i = 5\n",
    "data_to_predict = data[:i].reset_index(drop = True)\n",
    "predict_conditions = data_to_predict.prediction \n",
    "predict_conditions = np.array(predict_conditions)\n",
    "prediction = np.array(data_to_predict.drop(['prediction'],axis= 1))\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "data = data[i:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['prediction'], axis = 1)\n",
    "X = np.array(X)\n",
    "Y = data['prediction'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "Y = encoder.transform(Y)\n",
    "Y = to_categorical(Y)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(X,Y,test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86803 samples\n",
      "Epoch 1/20\n",
      "86803/86803 [==============================] - 49s 570us/sample - loss: 0.1015 - acc: 0.9698\n",
      "Epoch 2/20\n",
      "86803/86803 [==============================] - 45s 516us/sample - loss: 0.0625 - acc: 0.9822\n",
      "Epoch 3/20\n",
      "86803/86803 [==============================] - 44s 503us/sample - loss: 0.0605 - acc: 0.9838\n",
      "Epoch 4/20\n",
      "86803/86803 [==============================] - 44s 504us/sample - loss: 0.0581 - acc: 0.9847\n",
      "Epoch 5/20\n",
      "86803/86803 [==============================] - 44s 504us/sample - loss: 0.0579 - acc: 0.9843\n",
      "Epoch 6/20\n",
      "86803/86803 [==============================] - 44s 506us/sample - loss: 0.0633 - acc: 0.9841\n",
      "Epoch 7/20\n",
      "86803/86803 [==============================] - 41s 478us/sample - loss: 0.0876 - acc: 0.9830\n",
      "Epoch 8/20\n",
      "86803/86803 [==============================] - 45s 519us/sample - loss: 0.0607 - acc: 0.9856\n",
      "Epoch 9/20\n",
      "86803/86803 [==============================] - 48s 557us/sample - loss: 0.0616 - acc: 0.9860\n",
      "Epoch 10/20\n",
      "86803/86803 [==============================] - 45s 516us/sample - loss: 0.0587 - acc: 0.9855\n",
      "Epoch 11/20\n",
      "86803/86803 [==============================] - 44s 508us/sample - loss: 0.0552 - acc: 0.9859\n",
      "Epoch 12/20\n",
      "86803/86803 [==============================] - 44s 509us/sample - loss: 0.0527 - acc: 0.9864\n",
      "Epoch 13/20\n",
      "86803/86803 [==============================] - 45s 517us/sample - loss: 0.0527 - acc: 0.9866\n",
      "Epoch 14/20\n",
      "86803/86803 [==============================] - 48s 556us/sample - loss: 0.0606 - acc: 0.9873\n",
      "Epoch 15/20\n",
      "86803/86803 [==============================] - 49s 566us/sample - loss: 0.0530 - acc: 0.9874\n",
      "Epoch 16/20\n",
      "86803/86803 [==============================] - 44s 507us/sample - loss: 0.0483 - acc: 0.9875\n",
      "Epoch 17/20\n",
      "86803/86803 [==============================] - 44s 504us/sample - loss: 0.0488 - acc: 0.9875\n",
      "Epoch 18/20\n",
      "86803/86803 [==============================] - 44s 510us/sample - loss: 0.0470 - acc: 0.9884\n",
      "Epoch 19/20\n",
      "86803/86803 [==============================] - 46s 529us/sample - loss: 0.0465 - acc: 0.9881\n",
      "Epoch 20/20\n",
      "86803/86803 [==============================] - 44s 504us/sample - loss: 0.0467 - acc: 0.9883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17694322148>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = len(data.columns) - 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim = input_dim , activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'] )\n",
    "\n",
    "model.fit(train_x, train_y, epochs = 20, batch_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9645/9645 [==============================] - 1s 60us/sample - loss: 0.0344 - acc: 0.9927\n",
      "\n",
      "acc: 99.27%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_x, test_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(prediction)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "input = np.array([[9.472222222,0.89,1015.13]])\n",
    "predict = model.predict_classes(input)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "input = np.array([[-7.172222222,0.96,1005.25]])\n",
    "predict = model.predict_classes(input)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./my_model/assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save(\"./my_model/\",save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.load_model('./my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "input = np.array([[-7.172222222,0.96,1005.25]])\n",
    "predict = model2.predict_classes(input)\n",
    "print(predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
